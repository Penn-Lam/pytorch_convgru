{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvGRU Demo Notebook\n",
    "\n",
    "This notebook demonstrates the usage of ConvGRU (Convolutional Gated Recurrent Unit) implementation. ConvGRU is particularly useful for processing spatiotemporal data where both spatial and temporal dependencies need to be captured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from convgru import ConvGRU\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating a ConvGRU Model\n",
    "\n",
    "Let's create a ConvGRU model with multiple layers. Each layer can have different hidden sizes and kernel sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model parameters\n",
    "input_channels = 1  # number of input channels\n",
    "hidden_channels = [32, 64, 32]  # number of channels in each layer\n",
    "kernel_sizes = [3, 5, 3]  # kernel size for each layer\n",
    "n_layers = 3\n",
    "\n",
    "# Create the model\n",
    "model = ConvGRU(\n",
    "    input_size=input_channels,\n",
    "    hidden_sizes=hidden_channels,\n",
    "    kernel_sizes=kernel_sizes,\n",
    "    n_layers=n_layers\n",
    ")\n",
    "\n",
    "print(f\"Model architecture:\\n{model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Sample Data\n",
    "\n",
    "Let's create a simple moving circle animation as our input data to demonstrate how ConvGRU processes spatiotemporal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_moving_circle(frames=10, size=64, radius=3):\n",
    "    \"\"\"Create a sequence of frames with a moving circle.\"\"\"\n",
    "    sequence = np.zeros((frames, size, size))\n",
    "    center_x = size // 4\n",
    "    center_y = size // 2\n",
    "    \n",
    "    for t in range(frames):\n",
    "        # Update circle position\n",
    "        x = center_x + int(t * size/(2*frames))\n",
    "        y = center_y\n",
    "        \n",
    "        # Create meshgrid for the frame\n",
    "        xx, yy = np.mgrid[:size, :size]\n",
    "        circle = (xx - x) ** 2 + (yy - y) ** 2\n",
    "        sequence[t] = (circle < radius ** 2).astype(float)\n",
    "    \n",
    "    return sequence\n",
    "\n",
    "# Create sample sequence\n",
    "sequence = create_moving_circle()\n",
    "\n",
    "# Visualize a few frames\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15, 3))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(sequence[i*3], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'Frame {i*3}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Processing Data with ConvGRU\n",
    "\n",
    "Now let's process our sequence data with the ConvGRU model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Convert sequence to PyTorch tensor\n",
    "sequence_tensor = torch.FloatTensor(sequence)\n",
    "# Add batch and channel dimensions [batch, channel, time, height, width]\n",
    "sequence_tensor = sequence_tensor.unsqueeze(0).unsqueeze(0)\n",
    "print(f\"Input tensor shape: {sequence_tensor.shape}\")\n",
    "\n",
    "# Process each frame through the ConvGRU\n",
    "outputs = []\n",
    "hidden = None\n",
    "\n",
    "for t in range(sequence_tensor.size(2)):\n",
    "    # Get current frame [batch, channel, height, width]\n",
    "    current_frame = sequence_tensor[:, :, t, :, :]\n",
    "    # Process through ConvGRU\n",
    "    hidden = model(current_frame, hidden)\n",
    "    # Store output from last layer\n",
    "    outputs.append(hidden[-1].detach().numpy())\n",
    "\n",
    "outputs = np.array(outputs)\n",
    "print(f\"Output sequence shape: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing the Results\n",
    "\n",
    "Let's visualize some feature maps from the output to see what the ConvGRU has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize some feature maps from the last layer\n",
    "feature_idx = 0  # Index of feature map to visualize\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 6))\n",
    "\n",
    "# Plot input frames\n",
    "for i, ax in enumerate(axes[0]):\n",
    "    frame_idx = i * 3\n",
    "    ax.imshow(sequence[frame_idx], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'Input Frame {frame_idx}')\n",
    "\n",
    "# Plot corresponding feature maps\n",
    "for i, ax in enumerate(axes[1]):\n",
    "    frame_idx = i * 3\n",
    "    ax.imshow(outputs[frame_idx, 0, feature_idx], cmap='viridis')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'Feature Map {frame_idx}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Example\n",
    "\n",
    "Here's a simple example of how to train the ConvGRU model on a sequence prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a simple sequence prediction task\n",
    "class SequencePredictor(nn.Module):\n",
    "    def __init__(self, convgru_model):\n",
    "        super().__init__()\n",
    "        self.convgru = convgru_model\n",
    "        self.output_conv = nn.Conv2d(hidden_channels[-1], 1, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x, hidden=None):\n",
    "        # Process through ConvGRU\n",
    "        hidden = self.convgru(x, hidden)\n",
    "        # Use last layer's output\n",
    "        out = self.output_conv(hidden[-1])\n",
    "        return out, hidden\n",
    "\n",
    "# Create predictor model\n",
    "predictor = SequencePredictor(model)\n",
    "\n",
    "# Training parameters\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(predictor.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop example (just a few iterations for demonstration)\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Get current frame and next frame as target\n",
    "    for t in range(sequence_tensor.size(2)-1):\n",
    "        current_frame = sequence_tensor[:, :, t, :, :]\n",
    "        target_frame = sequence_tensor[:, :, t+1, :, :]\n",
    "        \n",
    "        # Forward pass\n",
    "        output, hidden = predictor(current_frame)\n",
    "        loss = criterion(output, target_frame)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward(retain_graph=True)\n",
    "    \n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demonstration shows how to:\n",
    "1. Create and initialize a ConvGRU model\n",
    "2. Prepare and process sequential data\n",
    "3. Visualize the inputs and feature maps\n",
    "4. Set up a training loop for sequence prediction\n",
    "\n",
    "The ConvGRU can be used for various spatiotemporal tasks such as:\n",
    "- Weather prediction\n",
    "- Video frame prediction\n",
    "- Satellite image analysis\n",
    "- Traffic flow prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
